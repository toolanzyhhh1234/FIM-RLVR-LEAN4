ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
Unsloth: UnslothBCOTrainer is already patched.
Unsloth: UnslothCPOTrainer is already patched.
Unsloth: UnslothDPOTrainer is already patched.
Unsloth: UnslothGKDTrainer is already patched.
Unsloth: UnslothGRPOTrainer is already patched.
Unsloth: UnslothKTOTrainer is already patched.
Unsloth: UnslothNashMDTrainer is already patched.
Unsloth: UnslothOnlineDPOTrainer is already patched.
Unsloth: UnslothORPOTrainer is already patched.
Unsloth: UnslothPPOTrainer is already patched.
Unsloth: UnslothPRMTrainer is already patched.
Unsloth: UnslothRewardTrainer is already patched.
Unsloth: UnslothRLOOTrainer is already patched.
Unsloth: UnslothSFTTrainer is already patched.
Unsloth: UnslothXPOTrainer is already patched.
Loading model: unsloth/gpt-oss-20b
==((====))==  Unsloth 2025.12.5: Fast Gpt_Oss patching. Transformers: 4.57.3.
   \\   /|    GRID A100D-40C. Num GPUs = 1. Max memory: 39.996 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = True]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:07,  2.36s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:04,  2.47s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:07<00:02,  2.36s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.60s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:07<00:00,  1.89s/it]
Unsloth: Making `model.base_model.model.model` require gradients
Loading dataset from data/data/train-00000-of-00001.parquet
Dataset rows (no filtering applied): 104155
Setting up dynamic curriculum transform...
Unsloth: We now expect `per_device_train_batch_size` * `gradient_accumulation_steps` * `world_size` to be a multiple of `num_generations`.
We will change the batch size of 1 to the `num_generations` of 4
Starting training with Curriculum...
The model is already on multiple devices. Skipping the move to device specified in `args`.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 104,155 | Num Epochs = 1 | Total steps = 5
O^O/ \_/ \    Batch size per device = 4 | Gradient accumulation steps = 1
\        /    Data Parallel GPUs = 1 | Total batch size (4 x 1 x 1) = 4
 "-____-"     Trainable parameters = 7,962,624 of 20,922,719,808 (0.04% trained)
  0%|          | 0/5 [00:00<?, ?it/s]`generation_config` default values have been modified to match model-specific defaults: {'max_length': 131072}. If this is not desired, please set these values explicitly.
Unsloth: Will smartly offload gradients to save VRAM!
 20%|â–ˆâ–ˆ        | 1/5 [10:44<42:59, 644.91s/it]                                              {'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 0.0, 'num_tokens': 3127.0, 'completions/mean_length': 666.75, 'completions/min_length': 300.0, 'completions/max_length': 1206.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 666.75, 'completions/min_terminated_length': 300.0, 'completions/max_terminated_length': 1206.0, 'rewards/lean_validity_reward/mean': 0.0, 'rewards/lean_validity_reward/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 666.75, 'kl': 0.0, 'epoch': 0.0}
 20%|â–ˆâ–ˆ        | 1/5 [10:44<42:59, 644.91s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [18:35<27:06, 542.21s/it]                                              {'loss': 0.0, 'grad_norm': 0.0, 'learning_rate': 5e-05, 'num_tokens': 6477.0, 'completions/mean_length': 722.5, 'completions/min_length': 658.0, 'completions/max_length': 868.0, 'completions/clipped_ratio': 0.0, 'completions/mean_terminated_length': 722.5, 'completions/min_terminated_length': 658.0, 'completions/max_terminated_length': 868.0, 'rewards/lean_validity_reward/mean': 0.0, 'rewards/lean_validity_reward/std': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 722.5, 'kl': 0.0, 'epoch': 0.0}
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [18:35<27:06, 542.21s/it]